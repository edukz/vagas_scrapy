import asyncio
import sys
import os

# Adicionar pasta src ao path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.scraper import scrape_catho_jobs
from src.filters import JobFilter, get_filter_configuration
from src.utils import save_results
from src.structured_logger import structured_logger, Component


async def main():
    """
    FunÃ§Ã£o principal - versÃ£o modularizada e organizada
    """
    # Inicializar sistema de logs
    structured_logger.log_system_info()
    structured_logger.info(
        "Application started",
        component=Component.MAIN,
        context={'version': '3.0', 'features': ['retry', 'fallback', 'validation', 'logging', 'circuit_breaker', 'metrics', 'alerts']}
    )
    
    print("=== WEB SCRAPER CATHO (VERSÃƒO MODULARIZADA) ===\n")
    print("âœ¨ Projeto reorganizado com arquitetura modular:")
    print("   ğŸ“¦ cache.py - Sistema de cache inteligente")
    print("   ğŸ“¦ scraper.py - LÃ³gica de scraping e extraÃ§Ã£o")
    print("   ğŸ“¦ filters.py - Sistema de filtros avanÃ§ados")
    print("   ğŸ“¦ navigation.py - NavegaÃ§Ã£o multi-pÃ¡gina")
    print("   ğŸ›¡ï¸ retry_system.py - Sistema de retry automÃ¡tico")
    print("   ğŸ¯ selector_fallback.py - Fallback de seletores")
    print("   ğŸ“‹ data_validator.py - ValidaÃ§Ã£o robusta de dados")
    print("   ğŸ“ structured_logger.py - Logs estruturados")
    print("   ğŸ”§ circuit_breaker.py - ProteÃ§Ã£o contra sobrecarga")
    print("   ğŸ“Š metrics_tracker.py - Monitoramento em tempo real")
    print("   ğŸš¨ alert_system.py - Alertas automÃ¡ticos")
    print("   ğŸ“¦ utils.py - UtilitÃ¡rios e performance")
    print("   ğŸ“¦ main.py - Interface principal (este arquivo)")
    
    print("\nğŸ” Recursos disponÃ­veis:")
    print("   â€¢ Sistema de filtragem avanÃ§ada")
    print("   â€¢ Cache inteligente (6h de validade)")
    print("   â€¢ Rate limiting adaptativo")
    print("   â€¢ NavegaÃ§Ã£o por mÃºltiplas pÃ¡ginas")
    print("   â€¢ Processamento paralelo")
    print("   â€¢ AnÃ¡lise automÃ¡tica de dados")
    print("   â€¢ MÃºltiplos formatos de saÃ­da\n")
    
    # Configurar filtros
    print("Deseja aplicar filtros Ã s vagas? (s/n)")
    apply_filters = input().strip().lower() in ['s', 'sim', 'y', 'yes']
    
    filters_config = {}
    if apply_filters:
        filters_config = get_filter_configuration()
    else:
        print("âœ“ Nenhum filtro serÃ¡ aplicado - todas as vagas serÃ£o coletadas")
    
    # Configurar performance
    print("\nâš¡ CONFIGURAÃ‡ÃƒO DE PERFORMANCE:")
    print("Quantas vagas processar simultaneamente? (1-5, padrÃ£o: 3)")
    try:
        max_concurrent = int(input("Digite o nÃºmero: ").strip() or "3")
        max_concurrent = max(1, min(5, max_concurrent))
    except:
        max_concurrent = 3
    
    print(f"âœ“ Processamento paralelo: {max_concurrent} vagas simultÃ¢neas")
    
    # Configurar pÃ¡ginas
    print("\nğŸ“„ CONFIGURAÃ‡ÃƒO DE PÃGINAS:")
    print("Quantas pÃ¡ginas analisar? (1-10, padrÃ£o: 5)")
    try:
        max_pages = int(input("Digite o nÃºmero: ").strip() or "5")
        max_pages = max(1, min(10, max_pages))
    except:
        max_pages = 5
    
    print(f"âœ“ NavegaÃ§Ã£o configurada: atÃ© {max_pages} pÃ¡ginas")
    
    # Executando o scraper
    print(f"\n{'='*60}")
    print("INICIANDO COLETA COM ARQUITETURA MODULAR...")
    print(f"{'='*60}")
    
    jobs = await scrape_catho_jobs(max_concurrent_jobs=max_concurrent, max_pages=max_pages)
    
    if jobs:
        print(f"\n{'='*60}")
        print(f"DADOS COLETADOS: {len(jobs)} vagas encontradas")
        print(f"{'='*60}")
        
        # Aplicar filtros e anÃ¡lise
        print("\nAplicando filtros e anÃ¡lise...")
        job_filter = JobFilter()
        
        if filters_config:
            filtered_jobs = job_filter.apply_filters(jobs, filters_config)
            print(f"âœ“ Filtros aplicados: {len(filtered_jobs)} vagas selecionadas")
        else:
            # Aplicar apenas anÃ¡lise sem filtros
            filtered_jobs = job_filter.apply_filters(jobs, {})
            print(f"âœ“ AnÃ¡lise aplicada a todas as {len(filtered_jobs)} vagas")
        
        jobs = filtered_jobs
        
        if jobs:
            print(f"\n{'='*60}")
            print(f"RESULTADO FINAL: {len(jobs)} vagas processadas")
            print(f"{'='*60}")
            
            # Salvando resultados
            save_results(jobs, filters_config)
            
            print(f"\nâœ… PROCESSAMENTO CONCLUÃDO COM SUCESSO!")
            print(f"ğŸ“ Arquivos organizados em subdiretÃ³rios")
            
            # Preview dos resultados
            print(f"\nğŸ”¥ PREVIEW DOS RESULTADOS:")
            if jobs:
                # Tecnologias mais demandadas
                all_techs = {}
                for job in jobs:
                    for tech in job.get('tecnologias_detectadas', []):
                        all_techs[tech] = all_techs.get(tech, 0) + 1
                
                if all_techs:
                    print(f"   ğŸ’» Top 5 tecnologias:")
                    for tech, count in sorted(all_techs.items(), key=lambda x: x[1], reverse=True)[:5]:
                        print(f"      - {tech}: {count} vagas")
                
                # AnÃ¡lise de nÃ­veis
                niveis = {}
                for job in jobs:
                    nivel = job.get('nivel_categorizado', 'NÃ£o categorizado')
                    niveis[nivel] = niveis.get(nivel, 0) + 1
                
                if niveis:
                    print(f"   ğŸ“Š DistribuiÃ§Ã£o por nÃ­vel:")
                    for nivel, count in sorted(niveis.items(), key=lambda x: x[1], reverse=True)[:3]:
                        print(f"      - {nivel.replace('_', ' ').title()}: {count} vagas")
        else:
            print("\nâš  Nenhuma vaga atendeu aos critÃ©rios de filtro especificados.")
            print("Tente ajustar os filtros ou executar sem filtros.")
    else:
        print("\nâœ— Nenhuma vaga foi encontrada no site.")


if __name__ == "__main__":
    asyncio.run(main())