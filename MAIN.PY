"""
Sistema Catho Job Scraper - Interface Melhorada
Vers√£o com menu interativo e visual
"""

import asyncio
import sys
import os

# Adicionar pasta src ao path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), ''))

from src.core.scraper import scrape_catho_jobs
from src.utils.filters import JobFilter, get_filter_configuration
from src.utils.utils import save_results
from src.systems.structured_logger import structured_logger, Component
from src.utils.menu_system import MenuSystem, Colors
from src.utils.settings_ui import settings_ui


async def run_scraping_with_config(config):
    """Executa scraping com configura√ß√£o fornecida"""
    menu = MenuSystem()
    
    # Inicializar sistema de logs
    structured_logger.log_system_info()
    structured_logger.info(
        "Application started",
        component=Component.MAIN,
        context={'version': '4.0', 'config': config}
    )
    
    try:
        # Selecionar scraper baseado no modo de performance
        performance_mode = config['performance_mode']
        
        if performance_mode == 1:
            # B√°sico
            menu.print_info_message("Iniciando scraper B√ÅSICO...")
            jobs = await scrape_catho_jobs(
                max_concurrent_jobs=config['max_concurrent'], 
                max_pages=config['max_pages']
            )
            
        elif performance_mode == 2:
            # Otimizado
            menu.print_info_message("Iniciando scraper OTIMIZADO...")
            from src.core.scraper_optimized import scrape_catho_jobs_optimized
            jobs = await scrape_catho_jobs_optimized(
                max_concurrent_jobs=config['max_concurrent'], 
                max_pages=config['max_pages'],
                incremental=config['incremental'],
                show_compression_stats=True,
                enable_deduplication=True
            )
            
        else:  # performance_mode == 3
            # M√°ximo
            menu.print_info_message("Iniciando scraper M√ÅXIMA PERFORMANCE...")
            from src.core.scraper_pooled import scrape_catho_jobs_pooled
            jobs = await scrape_catho_jobs_pooled(
                max_concurrent_jobs=config['max_concurrent'], 
                max_pages=config['max_pages'],
                incremental=config['incremental'],
                show_compression_stats=True,
                show_pool_stats=True,
                pool_min_size=2,
                pool_max_size=config['max_concurrent'] + 2,
                enable_deduplication=True
            )
        
        if jobs:
            menu.print_success_message(f"Coleta conclu√≠da! {len(jobs)} vagas encontradas")
            
            # Aplicar filtros se configurados
            if config.get('apply_filters') and config.get('filters'):
                print(f"\n{Colors.BLUE}üîç Aplicando filtros personalizados...{Colors.RESET}")
                job_filter = JobFilter()
                filtered_jobs = job_filter.apply_filters(jobs, config['filters'])
                menu.print_info_message(f"Filtros aplicados: {len(filtered_jobs)} vagas selecionadas")
                jobs = filtered_jobs
            else:
                # Aplicar apenas an√°lise sem filtros
                job_filter = JobFilter()
                jobs = job_filter.apply_filters(jobs, {})
                menu.print_info_message(f"An√°lise aplicada a todas as {len(jobs)} vagas")
            
            if jobs:
                # Salvar resultados
                print(f"\n{Colors.GREEN}üíæ Salvando resultados...{Colors.RESET}")
                save_results(jobs, config.get('filters', {}))
                
                menu.print_success_message("Processamento conclu√≠do com sucesso!")
                
                # Preview dos resultados
                print_results_preview(jobs, menu)
                
            else:
                menu.print_warning_message("Nenhuma vaga atendeu aos crit√©rios de filtro especificados.")
        else:
            menu.print_error_message("Nenhuma vaga foi encontrada no site.")
            
    except Exception as e:
        menu.print_error_message(f"Erro durante o processamento: {e}")
        import traceback
        traceback.print_exc()


def print_results_preview(jobs, menu):
    """Mostra preview dos resultados"""
    print(f"\n{Colors.BOLD}{Colors.CYAN}üî• PREVIEW DOS RESULTADOS:{Colors.RESET}")
    
    if jobs:
        # Tecnologias mais demandadas
        all_techs = {}
        for job in jobs:
            for tech in job.get('tecnologias_detectadas', []):
                all_techs[tech] = all_techs.get(tech, 0) + 1
        
        if all_techs:
            print(f"   {Colors.BOLD}üíª Top 5 tecnologias:{Colors.RESET}")
            for tech, count in sorted(all_techs.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"      - {Colors.GREEN}{tech}{Colors.RESET}: {count} vagas")
        
        # An√°lise de n√≠veis
        niveis = {}
        for job in jobs:
            nivel = job.get('nivel_categorizado', 'N√£o categorizado')
            niveis[nivel] = niveis.get(nivel, 0) + 1
        
        if niveis:
            print(f"   {Colors.BOLD}üìä Distribui√ß√£o por n√≠vel:{Colors.RESET}")
            for nivel, count in sorted(niveis.items(), key=lambda x: x[1], reverse=True)[:3]:
                print(f"      - {Colors.YELLOW}{nivel.replace('_', ' ').title()}{Colors.RESET}: {count} vagas")


async def handle_cache_operations(choice):
    """Manipula opera√ß√µes de cache"""
    menu = MenuSystem()
    
    try:
        from src.systems.compressed_cache import CompressedCache
        cache = CompressedCache()
        
        if choice == "1":  # Listar tudo
            results = cache.search_cache({})
            print(f"\n{Colors.BOLD}üìã TODAS AS ENTRADAS ({len(results)} encontradas):{Colors.RESET}")
            
            for i, entry in enumerate(results[:10], 1):  # Mostrar apenas 10 primeiros
                print(f"\n{Colors.BOLD}{i:2d}.{Colors.RESET} {entry.url[:60]}...")
                print(f"     üìÖ Data: {entry.timestamp.strftime('%Y-%m-%d %H:%M')}")
                print(f"     üíº Vagas: {Colors.GREEN}{entry.job_count}{Colors.RESET}")
                print(f"     üè¢ Empresas: {Colors.BLUE}{', '.join(entry.companies[:3])}{Colors.RESET}{'...' if len(entry.companies) > 3 else ''}")
            
            if len(results) > 10:
                print(f"\n{Colors.DIM}... e mais {len(results) - 10} entradas{Colors.RESET}")
        
        elif choice == "2":  # Por empresa
            company = input(f"{Colors.BOLD}Digite o nome da empresa: {Colors.RESET}").strip()
            if company:
                results = cache.search_cache({'companies': [company]})
                print(f"\n{Colors.BOLD}üè¢ Vagas da empresa '{company}' ({len(results)} encontradas):{Colors.RESET}")
                
                for i, entry in enumerate(results[:5], 1):
                    print(f"  {i}. {entry.url[:50]}... ({entry.job_count} vagas)")
            
        elif choice == "3":  # Por tecnologia
            tech = input(f"{Colors.BOLD}Digite a tecnologia: {Colors.RESET}").strip()
            if tech:
                results = cache.search_cache({'technologies': [tech]})
                print(f"\n{Colors.BOLD}üíª Vagas com '{tech}' ({len(results)} encontradas):{Colors.RESET}")
                
                for i, entry in enumerate(results[:5], 1):
                    print(f"  {i}. {entry.url[:50]}... ({entry.job_count} vagas)")
        
        elif choice == "4":  # Por localiza√ß√£o
            location = input(f"{Colors.BOLD}Digite a localiza√ß√£o: {Colors.RESET}").strip()
            if location:
                results = cache.search_cache({'locations': [location]})
                print(f"\n{Colors.BOLD}üìç Vagas em '{location}' ({len(results)} encontradas):{Colors.RESET}")
                
                for i, entry in enumerate(results[:5], 1):
                    print(f"  {i}. {entry.url[:50]}... ({entry.job_count} vagas)")
        
        elif choice == "5":  # Estat√≠sticas
            cache.print_compression_report()
            cache.index.print_summary()
        
        elif choice == "6":  # Top rankings
            print(f"\n{Colors.BOLD}üèÜ TOP RANKINGS:{Colors.RESET}")
            
            print(f"\n{Colors.BOLD}üè¢ TOP 10 EMPRESAS:{Colors.RESET}")
            top_companies = cache.get_top_companies(10)
            for i, (company, count) in enumerate(top_companies, 1):
                print(f"   {i:2d}. {Colors.GREEN}{company}{Colors.RESET}: {count} vagas")
            
            print(f"\n{Colors.BOLD}üíª TOP 10 TECNOLOGIAS:{Colors.RESET}")
            top_techs = cache.get_top_technologies(10)
            for i, (tech, count) in enumerate(top_techs, 1):
                print(f"   {i:2d}. {Colors.BLUE}{tech}{Colors.RESET}: {count} vagas")
        
        print(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
        input()
        
    except Exception as e:
        menu.print_error_message(f"Erro ao acessar cache: {e}")
        input()


async def handle_clean_data():
    """Limpa dados do sistema"""
    menu = MenuSystem()
    
    menu.print_warning_message("ATEN√á√ÉO: Isso remover√° todos os dados armazenados!")
    
    if menu.get_user_bool("Tem certeza que deseja continuar?", False):
        import shutil
        
        # Remover diret√≥rios de cache e checkpoint
        directories_to_clean = [
            "data/cache",
            "data/checkpoints"
        ]
        
        # Remover tamb√©m arquivos de deduplica√ß√£o
        files_to_clean = [
            "data/deduplication_stats.json",
            "data/known_jobs.json"
        ]
        
        cleaned = 0
        for directory in directories_to_clean:
            if os.path.exists(directory):
                try:
                    shutil.rmtree(directory)
                    print(f"‚úÖ {directory} removido")
                    cleaned += 1
                except Exception as e:
                    print(f"‚ùå Erro ao remover {directory}: {e}")
        
        # Remover arquivos de deduplica√ß√£o
        for file_path in files_to_clean:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    print(f"‚úÖ {file_path} removido")
                    cleaned += 1
                except Exception as e:
                    print(f"‚ùå Erro ao remover {file_path}: {e}")
        
        if cleaned > 0:
            menu.print_success_message(f"Cache limpo! {cleaned} itens removidos")
            print("üîÑ Agora o scraping processar√° todas as p√°ginas do zero")
        else:
            menu.print_info_message("Nenhum cache encontrado para limpar")
    else:
        menu.print_info_message("Limpeza cancelada")
    
    print(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
    input()


async def handle_deduplication():
    """Executa deduplica√ß√£o de arquivos"""
    menu = MenuSystem()
    
    print(f"\n{Colors.BOLD}üßπ SISTEMA DE DEDUPLICA√á√ÉO{Colors.RESET}")
    print("Esta opera√ß√£o ir√°:")
    print("  ‚Ä¢ Escanear todos os arquivos JSON em data/")
    print("  ‚Ä¢ Remover vagas duplicadas")
    print("  ‚Ä¢ Criar backup dos arquivos originais (.bak)")
    print("  ‚Ä¢ Exibir relat√≥rio detalhado")
    
    if menu.get_user_bool("Deseja continuar?", True):
        try:
            from src.systems.deduplicator import JobDeduplicator
            
            deduplicator = JobDeduplicator()
            removed_count = deduplicator.clean_existing_files("data")
            
            if removed_count > 0:
                menu.print_success_message(f"Deduplica√ß√£o conclu√≠da: {removed_count} duplicatas removidas!")
                deduplicator.print_stats()
            else:
                menu.print_info_message("Nenhuma duplicata encontrada ou nenhum arquivo para processar")
        except Exception as e:
            menu.print_error_message(f"Erro durante deduplica√ß√£o: {e}")
    else:
        menu.print_info_message("Deduplica√ß√£o cancelada")
    
    print(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
    input()


async def start_api_server():
    """Inicia servidor da API"""
    menu = MenuSystem()
    
    menu.print_info_message("Iniciando servidor da API REST...")
    print(f"\n{Colors.BOLD}üåê SERVIDOR API{Colors.RESET}")
    print("  ‚Ä¢ FastAPI com documenta√ß√£o autom√°tica")
    print("  ‚Ä¢ Autentica√ß√£o JWT")
    print("  ‚Ä¢ Background tasks para scraping")
    print("  ‚Ä¢ Rate limiting e monitoramento")
    print()
    
    try:
        import uvicorn
        from api.main import app
        
        print(f"{Colors.GREEN}üöÄ Iniciando API em http://localhost:8000{Colors.RESET}")
        print(f"{Colors.BLUE}üìö Documenta√ß√£o: http://localhost:8000/docs{Colors.RESET}")
        print(f"{Colors.CYAN}üìñ ReDoc: http://localhost:8000/redoc{Colors.RESET}")
        print()
        print(f"{Colors.DIM}Pressione Ctrl+C para parar o servidor{Colors.RESET}")
        
        uvicorn.run(
            "api.main:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
            log_level="info"
        )
        
    except ImportError:
        menu.print_error_message("Depend√™ncias da API n√£o encontradas")
        menu.print_info_message("Execute: pip install uvicorn fastapi")
    except Exception as e:
        menu.print_error_message(f"Erro ao iniciar API: {e}")
    
    print(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
    input()


async def handle_cv_analysis():
    """Gerencia o menu de an√°lise de CV"""
    try:
        from src.utils.cv_interface import run_cv_interface
        run_cv_interface()
    except Exception as e:
        menu = MenuSystem()
        menu.print_error_message(f"Erro no sistema de an√°lise de CV: {e}")
        input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def handle_settings_menu():
    """Gerencia o menu de configura√ß√µes avan√ßadas"""
    try:
        settings_ui.show_main_settings_menu()
    except Exception as e:
        menu = MenuSystem()
        menu.print_error_message(f"Erro no sistema de configura√ß√µes: {e}")
        input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def handle_statistics_dashboard():
    """Exibe dashboard completo de estat√≠sticas"""
    menu = MenuSystem()
    
    while True:
        try:
            choice = await show_statistics_menu(menu)
            
            if choice == "0":  # Voltar
                break
            elif choice == "1":  # Vis√£o Geral
                await show_general_overview(menu)
            elif choice == "2":  # An√°lise de Vagas
                await show_job_analysis(menu)
            elif choice == "3":  # Tecnologias
                await show_technology_stats(menu)
            elif choice == "4":  # Empresas
                await show_company_stats(menu)
            elif choice == "5":  # Localiza√ß√£o
                await show_location_stats(menu)
            elif choice == "6":  # Sal√°rios
                await show_salary_stats(menu)
            elif choice == "7":  # Cache e Performance
                await show_performance_stats(menu)
            elif choice == "8":  # Hist√≥rico
                await show_historical_data(menu)
                
        except Exception as e:
            menu.print_error_message(f"Erro no dashboard: {e}")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_statistics_menu(menu):
    """Mostra menu principal de estat√≠sticas"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.BLUE}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}‚ïë{Colors.RESET}                    {Colors.BOLD}{Colors.WHITE}üìä DASHBOARD DE ESTAT√çSTICAS - v4.0.0{Colors.RESET}                    {Colors.BOLD}{Colors.BLUE}‚ïë{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}‚ïë{Colors.RESET}                {Colors.GREEN}Sistema Completo de An√°lise e M√©tricas{Colors.RESET}                 {Colors.BOLD}{Colors.BLUE}‚ïë{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù{Colors.RESET}")
    print()
    
    # Status r√°pido do sistema
    await print_quick_stats(menu)
    
    # Menu de op√ß√µes
    print(f"{Colors.BOLD}üìã CATEGORIAS DE AN√ÅLISE{Colors.RESET}")
    print()
    
    print(f"{Colors.DIM}‚îå‚îÄ An√°lises Principais ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[1]{Colors.RESET} üéØ VIS√ÉO GERAL      ‚îÇ M√©tricas gerais do sistema e resumo    {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[2]{Colors.RESET} üíº AN√ÅLISE DE VAGAS ‚îÇ Distribui√ß√£o, n√≠veis, modalidades      {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[3]{Colors.RESET} üíª TECNOLOGIAS      ‚îÇ Stack mais demandado, tend√™ncias        {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[4]{Colors.RESET} üè¢ EMPRESAS         ‚îÇ Top contratantes, distribui√ß√£o          {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò{Colors.RESET}")
    print()
    
    print(f"{Colors.DIM}‚îå‚îÄ An√°lises Detalhadas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[5]{Colors.RESET} üìç LOCALIZA√á√ÉO      ‚îÇ Distribui√ß√£o geogr√°fica de vagas        {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[6]{Colors.RESET} üí∞ SAL√ÅRIOS         ‚îÇ Faixas salariais, an√°lise por n√≠vel     {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[7]{Colors.RESET} ‚ö° PERFORMANCE      ‚îÇ Cache, tempos, efici√™ncia do sistema    {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}[8]{Colors.RESET} üìà HIST√ìRICO        ‚îÇ Evolu√ß√£o temporal e tend√™ncias          {Colors.DIM}‚îÇ{Colors.RESET}")
    print(f"{Colors.DIM}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò{Colors.RESET}")
    print()
    
    print(f"  {Colors.BOLD}[0]{Colors.RESET} ‚¨ÖÔ∏è  VOLTAR          Retornar ao menu principal")
    print()
    
    return menu.get_user_choice("Escolha uma categoria", "0", 
                               ["0", "1", "2", "3", "4", "5", "6", "7", "8"])


async def print_quick_stats(menu):
    """Imprime estat√≠sticas r√°pidas no cabe√ßalho"""
    try:
        # Contar arquivos de resultados
        import os
        import json
        from pathlib import Path
        
        results_dir = Path("data/resultados/json")
        total_files = 0
        total_jobs = 0
        latest_date = "N/A"
        
        if results_dir.exists():
            files = list(results_dir.glob("*.json"))
            total_files = len(files)
            
            # Contar total de vagas e encontrar data mais recente
            for file_path in files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, list):
                        total_jobs += len(data)
                    
                    # Extrair data do nome do arquivo
                    if "_" in file_path.name:
                        date_part = file_path.name.split("_")[-1].replace(".json", "")
                        if len(date_part) >= 8:
                            formatted_date = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                            if latest_date == "N/A" or formatted_date > latest_date:
                                latest_date = formatted_date
                except:
                    continue
        
        # Cache info
        cache_dir = Path("data/cache")
        cache_files = len(list(cache_dir.glob("*.json"))) if cache_dir.exists() else 0
        
        # Status do sistema
        print(f"{Colors.DIM}‚îå‚îÄ Status R√°pido ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê{Colors.RESET}")
        print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}üìä Total de Vagas:{Colors.RESET} {Colors.GREEN}{total_jobs:,}{Colors.RESET}{' ' * max(0, 15-len(f'{total_jobs:,}'))} ‚îÇ {Colors.BOLD}üìÖ √öltima Coleta:{Colors.RESET} {Colors.CYAN}{latest_date}{Colors.RESET}{' ' * max(0, 15-len(latest_date))} {Colors.DIM}‚îÇ{Colors.RESET}")
        print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.BOLD}üìÅ Arquivos:{Colors.RESET} {Colors.YELLOW}{total_files}{Colors.RESET}{' ' * max(0, 20-len(str(total_files)))} ‚îÇ {Colors.BOLD}üíæ Cache:{Colors.RESET} {Colors.BLUE}{cache_files} arquivo(s){Colors.RESET}{' ' * max(0, 15-len(f'{cache_files} arquivo(s)'))} {Colors.DIM}‚îÇ{Colors.RESET}")
        print(f"{Colors.DIM}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò{Colors.RESET}")
        print()
        
    except Exception as e:
        print(f"{Colors.DIM}‚îå‚îÄ Status R√°pido ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê{Colors.RESET}")
        print(f"{Colors.DIM}‚îÇ{Colors.RESET} {Colors.RED}‚ùå Erro ao carregar estat√≠sticas r√°pidas: {str(e)[:40]}...{Colors.RESET}{' ' * 20} {Colors.DIM}‚îÇ{Colors.RESET}")
        print(f"{Colors.DIM}‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò{Colors.RESET}")
        print()


async def show_general_overview(menu):
    """Exibe vis√£o geral do sistema"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.GREEN}üéØ VIS√ÉO GERAL DO SISTEMA{Colors.RESET}")
    print()
    
    try:
        import json
        from pathlib import Path
        from datetime import datetime
        
        # Carregar todos os dados
        all_jobs = []
        results_dir = Path("data/resultados/json")
        
        if results_dir.exists():
            for file_path in results_dir.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, list):
                        all_jobs.extend(data)
                except:
                    continue
        
        total_jobs = len(all_jobs)
        
        if total_jobs == 0:
            menu.print_warning_message("Nenhum dado encontrado. Execute o scraping primeiro.")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
            return
        
        # An√°lises gerais
        print(f"{Colors.BOLD}üìä M√âTRICAS GERAIS{Colors.RESET}")
        print(f"   Total de vagas coletadas: {Colors.GREEN}{total_jobs:,}{Colors.RESET}")
        
        # Tecnologias mais demandadas
        tech_count = {}
        for job in all_jobs:
            for tech in job.get('tecnologias_detectadas', []):
                tech_count[tech] = tech_count.get(tech, 0) + 1
        
        if tech_count:
            print(f"\n{Colors.BOLD}üíª TOP 10 TECNOLOGIAS MAIS DEMANDADAS{Colors.RESET}")
            for i, (tech, count) in enumerate(sorted(tech_count.items(), key=lambda x: x[1], reverse=True)[:10], 1):
                percentage = (count / total_jobs) * 100
                print(f"   {i:2d}. {Colors.CYAN}{tech:<20}{Colors.RESET} {Colors.GREEN}{count:4d}{Colors.RESET} vagas ({percentage:4.1f}%)")
        
        # Empresas que mais contratam
        company_count = {}
        for job in all_jobs:
            company = job.get('empresa', 'N/A')
            if company and company != 'N/A':
                company_count[company] = company_count.get(company, 0) + 1
        
        if company_count:
            print(f"\n{Colors.BOLD}üè¢ TOP 10 EMPRESAS QUE MAIS CONTRATAM{Colors.RESET}")
            for i, (company, count) in enumerate(sorted(company_count.items(), key=lambda x: x[1], reverse=True)[:10], 1):
                print(f"   {i:2d}. {Colors.YELLOW}{company[:30]:<30}{Colors.RESET} {Colors.GREEN}{count:3d}{Colors.RESET} vagas")
        
        # Modalidades de trabalho
        modalidade_count = {}
        for job in all_jobs:
            modalidade = job.get('modalidade_trabalho', 'N/A')
            modalidade_count[modalidade] = modalidade_count.get(modalidade, 0) + 1
        
        if modalidade_count:
            print(f"\n{Colors.BOLD}üè† MODALIDADES DE TRABALHO{Colors.RESET}")
            for modalidade, count in sorted(modalidade_count.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total_jobs) * 100
                print(f"   ‚Ä¢ {Colors.BLUE}{modalidade:<20}{Colors.RESET} {Colors.GREEN}{count:4d}{Colors.RESET} vagas ({percentage:4.1f}%)")
        
        # N√≠veis de experi√™ncia
        nivel_count = {}
        for job in all_jobs:
            nivel = job.get('nivel_categorizado', 'N/A')
            nivel_count[nivel] = nivel_count.get(nivel, 0) + 1
        
        if nivel_count:
            print(f"\n{Colors.BOLD}üìà DISTRIBUI√á√ÉO POR N√çVEL{Colors.RESET}")
            for nivel, count in sorted(nivel_count.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total_jobs) * 100
                nivel_display = nivel.replace('_', ' ').title() if nivel != 'N/A' else 'N√£o Categorizado'
                print(f"   ‚Ä¢ {Colors.MAGENTA}{nivel_display:<20}{Colors.RESET} {Colors.GREEN}{count:4d}{Colors.RESET} vagas ({percentage:4.1f}%)")
        
    except Exception as e:
        menu.print_error_message(f"Erro ao gerar vis√£o geral: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_job_analysis(menu):
    """An√°lise detalhada de vagas"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.BLUE}üíº AN√ÅLISE DETALHADA DE VAGAS{Colors.RESET}")
    print()
    
    try:
        import json
        from pathlib import Path
        
        # Carregar dados
        all_jobs = []
        results_dir = Path("data/resultados/json")
        
        if results_dir.exists():
            for file_path in results_dir.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, list):
                        all_jobs.extend(data)
                except:
                    continue
        
        if not all_jobs:
            menu.print_warning_message("Nenhum dado encontrado.")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
            return
        
        total_jobs = len(all_jobs)
        
        # An√°lise de descri√ß√µes
        desc_stats = {
            'with_description': 0,
            'avg_length': 0,
            'with_requirements': 0,
            'with_benefits': 0
        }
        
        total_length = 0
        for job in all_jobs:
            desc = job.get('descricao', '')
            if desc and desc.strip():
                desc_stats['with_description'] += 1
                total_length += len(desc)
                
                if any(word in desc.lower() for word in ['requisito', 'experi√™ncia', 'conhecimento']):
                    desc_stats['with_requirements'] += 1
                    
                if any(word in desc.lower() for word in ['benef√≠cio', 'vale', 'plano', 'conv√™nio']):
                    desc_stats['with_benefits'] += 1
        
        if desc_stats['with_description'] > 0:
            desc_stats['avg_length'] = total_length // desc_stats['with_description']
        
        print(f"{Colors.BOLD}üìÑ QUALIDADE DOS DADOS{Colors.RESET}")
        print(f"   Vagas com descri√ß√£o: {Colors.GREEN}{desc_stats['with_description']:,}{Colors.RESET} ({(desc_stats['with_description']/total_jobs)*100:.1f}%)")
        print(f"   Tamanho m√©dio da descri√ß√£o: {Colors.CYAN}{desc_stats['avg_length']:,}{Colors.RESET} caracteres")
        print(f"   Com requisitos detalhados: {Colors.YELLOW}{desc_stats['with_requirements']:,}{Colors.RESET} ({(desc_stats['with_requirements']/total_jobs)*100:.1f}%)")
        print(f"   Com benef√≠cios mencionados: {Colors.BLUE}{desc_stats['with_benefits']:,}{Colors.RESET} ({(desc_stats['with_benefits']/total_jobs)*100:.1f}%)")
        
        # An√°lise de campos obrigat√≥rios
        print(f"\n{Colors.BOLD}‚úÖ COMPLETUDE DOS DADOS{Colors.RESET}")
        fields_analysis = {
            'titulo': 'T√≠tulo da vaga',
            'empresa': 'Nome da empresa',
            'localizacao': 'Localiza√ß√£o',
            'modalidade_trabalho': 'Modalidade de trabalho',
            'tecnologias_detectadas': 'Tecnologias'
        }
        
        for field, label in fields_analysis.items():
            count = sum(1 for job in all_jobs if job.get(field) and str(job.get(field)).strip() not in ['', 'N/A', '[]'])
            percentage = (count / total_jobs) * 100
            print(f"   {label:<25}: {Colors.GREEN if percentage > 80 else Colors.YELLOW if percentage > 50 else Colors.RED}{count:,}{Colors.RESET} ({percentage:5.1f}%)")
        
        # Distribui√ß√£o temporal (se tiver dados de data)
        dates_found = []
        for job in all_jobs:
            date_str = job.get('data_coleta', '')
            if date_str:
                try:
                    dates_found.append(date_str[:10])  # YYYY-MM-DD
                except:
                    continue
        
        if dates_found:
            from collections import Counter
            date_counts = Counter(dates_found)
            print(f"\n{Colors.BOLD}üìÖ DISTRIBUI√á√ÉO TEMPORAL{Colors.RESET}")
            for date, count in sorted(date_counts.items(), reverse=True)[:7]:
                print(f"   {date}: {Colors.GREEN}{count:,}{Colors.RESET} vagas")
        
    except Exception as e:
        menu.print_error_message(f"Erro na an√°lise de vagas: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_technology_stats(menu):
    """Estat√≠sticas de tecnologias"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.CYAN}üíª AN√ÅLISE DE TECNOLOGIAS{Colors.RESET}")
    print()
    
    try:
        import json
        from pathlib import Path
        from collections import Counter
        
        # Carregar dados
        all_jobs = []
        results_dir = Path("data/resultados/json")
        
        if results_dir.exists():
            for file_path in results_dir.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, list):
                        all_jobs.extend(data)
                except:
                    continue
        
        if not all_jobs:
            menu.print_warning_message("Nenhum dado encontrado.")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
            return
        
        # An√°lise de tecnologias
        all_techs = []
        for job in all_jobs:
            techs = job.get('tecnologias_detectadas', [])
            all_techs.extend(techs)
        
        tech_counter = Counter(all_techs)
        total_jobs = len(all_jobs)
        
        if tech_counter:
            print(f"{Colors.BOLD}üèÜ TOP 20 TECNOLOGIAS MAIS DEMANDADAS{Colors.RESET}")
            print()
            
            # Categorizar tecnologias
            categories = {
                'languages': ['Python', 'Java', 'JavaScript', 'C#', 'PHP', 'Ruby', 'Go', 'Rust', 'C++', 'TypeScript'],
                'frameworks': ['React', 'Angular', 'Vue', 'Django', 'Flask', 'Spring', 'Laravel', 'Express'],
                'databases': ['MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'SQL Server'],
                'cloud': ['AWS', 'Azure', 'Google Cloud', 'Docker', 'Kubernetes'],
                'tools': ['Git', 'Jenkins', 'Jira', 'Confluence']
            }
            
            for i, (tech, count) in enumerate(tech_counter.most_common(20), 1):
                percentage = (count / total_jobs) * 100
                
                # Determinar categoria
                category = 'üîß'
                for cat, items in categories.items():
                    if any(item.lower() in tech.lower() for item in items):
                        if cat == 'languages':
                            category = 'üêç'
                        elif cat == 'frameworks':
                            category = '‚öõÔ∏è'
                        elif cat == 'databases':
                            category = 'üíæ'
                        elif cat == 'cloud':
                            category = '‚òÅÔ∏è'
                        break
                
                print(f"   {i:2d}. {category} {Colors.CYAN}{tech:<25}{Colors.RESET} {Colors.GREEN}{count:4d}{Colors.RESET} vagas ({percentage:5.1f}%)")
            
            # An√°lise por categoria
            print(f"\n{Colors.BOLD}üìä AN√ÅLISE POR CATEGORIA{Colors.RESET}")
            category_stats = {cat: 0 for cat in categories.keys()}
            
            for tech, count in tech_counter.items():
                for cat, items in categories.items():
                    if any(item.lower() in tech.lower() for item in items):
                        category_stats[cat] += count
                        break
            
            category_names = {
                'languages': 'Linguagens de Programa√ß√£o',
                'frameworks': 'Frameworks e Bibliotecas',
                'databases': 'Bancos de Dados',
                'cloud': 'Cloud e DevOps',
                'tools': 'Ferramentas de Desenvolvimento'
            }
            
            for cat, total in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
                if total > 0:
                    print(f"   {category_names[cat]:<30}: {Colors.GREEN}{total:4d}{Colors.RESET} men√ß√µes")
        
    except Exception as e:
        menu.print_error_message(f"Erro na an√°lise de tecnologias: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_company_stats(menu):
    """Estat√≠sticas de empresas"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.YELLOW}üè¢ AN√ÅLISE DE EMPRESAS{Colors.RESET}")
    print()
    
    try:
        import json
        from pathlib import Path
        from collections import Counter
        
        # Carregar dados
        all_jobs = []
        results_dir = Path("data/resultados/json")
        
        if results_dir.exists():
            for file_path in results_dir.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, list):
                        all_jobs.extend(data)
                except:
                    continue
        
        if not all_jobs:
            menu.print_warning_message("Nenhum dado encontrado.")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
            return
        
        # An√°lise de empresas
        companies = [job.get('empresa', 'N/A') for job in all_jobs if job.get('empresa') and job.get('empresa') != 'N/A']
        company_counter = Counter(companies)
        total_jobs = len(all_jobs)
        total_companies = len(company_counter)
        
        print(f"{Colors.BOLD}üìà ESTAT√çSTICAS GERAIS{Colors.RESET}")
        print(f"   Total de empresas √∫nicas: {Colors.GREEN}{total_companies:,}{Colors.RESET}")
        print(f"   M√©dia de vagas por empresa: {Colors.CYAN}{len(companies)/total_companies:.1f}{Colors.RESET}")
        
        if company_counter:
            print(f"\n{Colors.BOLD}üèÜ TOP 15 EMPRESAS QUE MAIS CONTRATAM{Colors.RESET}")
            print()
            
            for i, (company, count) in enumerate(company_counter.most_common(15), 1):
                percentage = (count / total_jobs) * 100
                company_display = company[:40] + "..." if len(company) > 40 else company
                
                # Determinar porte da empresa baseado no n√∫mero de vagas
                if count >= 50:
                    size_icon = "üè≠"  # Grande porte
                elif count >= 20:
                    size_icon = "üè¢"  # M√©dio porte
                elif count >= 5:
                    size_icon = "üè™"  # Pequeno/M√©dio porte
                else:
                    size_icon = "üè¨"  # Pequeno porte
                
                print(f"   {i:2d}. {size_icon} {Colors.YELLOW}{company_display:<42}{Colors.RESET} {Colors.GREEN}{count:3d}{Colors.RESET} vagas ({percentage:4.1f}%)")
            
            # An√°lise de distribui√ß√£o
            print(f"\n{Colors.BOLD}üìä DISTRIBUI√á√ÉO DE VAGAS POR EMPRESA{Colors.RESET}")
            
            # Categorias de empresas por n√∫mero de vagas
            categories = {
                'Grandes (50+ vagas)': len([c for c in company_counter.values() if c >= 50]),
                'M√©dias (20-49 vagas)': len([c for c in company_counter.values() if 20 <= c < 50]),
                'Pequenas (5-19 vagas)': len([c for c in company_counter.values() if 5 <= c < 20]),
                'Micro (1-4 vagas)': len([c for c in company_counter.values() if 1 <= c < 5])
            }
            
            for category, count in categories.items():
                percentage = (count / total_companies) * 100 if total_companies > 0 else 0
                print(f"   {category:<20}: {Colors.BLUE}{count:3d}{Colors.RESET} empresas ({percentage:4.1f}%)")
        
    except Exception as e:
        menu.print_error_message(f"Erro na an√°lise de empresas: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_location_stats(menu):
    """Estat√≠sticas de localiza√ß√£o"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.MAGENTA}üìç AN√ÅLISE DE LOCALIZA√á√ÉO{Colors.RESET}")
    print()
    
    try:
        import json
        from pathlib import Path
        from collections import Counter
        
        # Carregar dados
        all_jobs = []
        results_dir = Path("data/resultados/json")
        
        if results_dir.exists():
            for file_path in results_dir.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if isinstance(data, list):
                        all_jobs.extend(data)
                except:
                    continue
        
        if not all_jobs:
            menu.print_warning_message("Nenhum dado encontrado.")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
            return
        
        # An√°lise de localiza√ß√£o
        locations = []
        states = []
        cities = []
        
        for job in all_jobs:
            location = job.get('localizacao', '')
            if location and location != 'N/A':
                locations.append(location)
                
                # Tentar extrair estado e cidade
                if ',' in location:
                    parts = location.split(',')
                    if len(parts) >= 2:
                        city = parts[0].strip()
                        state = parts[-1].strip()
                        cities.append(city)
                        states.append(state)
        
        location_counter = Counter(locations)
        state_counter = Counter(states)
        city_counter = Counter(cities)
        total_jobs = len(all_jobs)
        
        print(f"{Colors.BOLD}üó∫Ô∏è DISTRIBUI√á√ÉO GEOGR√ÅFICA{Colors.RESET}")
        
        if state_counter:
            print(f"\n{Colors.BOLD}üèõÔ∏è TOP 10 ESTADOS{Colors.RESET}")
            for i, (state, count) in enumerate(state_counter.most_common(10), 1):
                percentage = (count / total_jobs) * 100
                print(f"   {i:2d}. {Colors.MAGENTA}{state:<20}{Colors.RESET} {Colors.GREEN}{count:4d}{Colors.RESET} vagas ({percentage:5.1f}%)")
        
        if city_counter:
            print(f"\n{Colors.BOLD}üèôÔ∏è TOP 15 CIDADES{Colors.RESET}")
            for i, (city, count) in enumerate(city_counter.most_common(15), 1):
                percentage = (count / total_jobs) * 100
                print(f"   {i:2d}. {Colors.CYAN}{city:<25}{Colors.RESET} {Colors.GREEN}{count:4d}{Colors.RESET} vagas ({percentage:5.1f}%)")
        
        # An√°lise de modalidade por localiza√ß√£o
        remote_keywords = ['remoto', 'home office', 'home-office', 'remota']
        hybrid_keywords = ['h√≠brido', 'hibrido']
        
        remote_count = 0
        hybrid_count = 0
        onsite_count = 0
        
        for job in all_jobs:
            modalidade = job.get('modalidade_trabalho', '').lower()
            location = job.get('localizacao', '').lower()
            
            if any(keyword in modalidade or keyword in location for keyword in remote_keywords):
                remote_count += 1
            elif any(keyword in modalidade for keyword in hybrid_keywords):
                hybrid_count += 1
            else:
                onsite_count += 1
        
        print(f"\n{Colors.BOLD}üè† MODALIDADES DE TRABALHO{Colors.RESET}")
        total_classified = remote_count + hybrid_count + onsite_count
        if total_classified > 0:
            print(f"   Remoto: {Colors.GREEN}{remote_count:4d}{Colors.RESET} vagas ({(remote_count/total_classified)*100:5.1f}%)")
            print(f"   H√≠brido: {Colors.YELLOW}{hybrid_count:4d}{Colors.RESET} vagas ({(hybrid_count/total_classified)*100:5.1f}%)")
            print(f"   Presencial: {Colors.BLUE}{onsite_count:4d}{Colors.RESET} vagas ({(onsite_count/total_classified)*100:5.1f}%)")
        
    except Exception as e:
        menu.print_error_message(f"Erro na an√°lise de localiza√ß√£o: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_salary_stats(menu):
    """Estat√≠sticas de sal√°rios"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.GREEN}üí∞ AN√ÅLISE DE SAL√ÅRIOS{Colors.RESET}")
    print()
    
    menu.print_info_message("An√°lise de sal√°rios ainda n√£o implementada - dados de sal√°rio n√£o coletados sistematicamente.")
    print("\nüí° Esta funcionalidade ser√° implementada quando o scraper come√ßar a coletar dados salariais.")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_performance_stats(menu):
    """Estat√≠sticas de performance do sistema"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.RED}‚ö° PERFORMANCE E CACHE{Colors.RESET}")
    print()
    
    try:
        import json
        import os
        from pathlib import Path
        
        # An√°lise do cache
        cache_dir = Path("data/cache")
        cache_stats = {
            'total_files': 0,
            'total_size': 0,
            'index_size': 0
        }
        
        if cache_dir.exists():
            cache_files = list(cache_dir.glob("*.json"))
            cache_stats['total_files'] = len(cache_files)
            
            for file_path in cache_files:
                try:
                    cache_stats['total_size'] += file_path.stat().st_size
                except:
                    continue
            
            # Verificar √≠ndice do cache
            index_file = cache_dir / "cache_index.json"
            if index_file.exists():
                cache_stats['index_size'] = index_file.stat().st_size
        
        # An√°lise dos checkpoints
        checkpoint_dir = Path("data/checkpoints")
        checkpoint_stats = {
            'incremental_available': False,
            'stats_available': False
        }
        
        if checkpoint_dir.exists():
            checkpoint_stats['incremental_available'] = (checkpoint_dir / "incremental_checkpoint.json").exists()
            checkpoint_stats['stats_available'] = (checkpoint_dir / "incremental_stats.json").exists()
        
        # An√°lise dos resultados
        results_dir = Path("data/resultados")
        results_stats = {
            'json_files': 0,
            'csv_files': 0,
            'txt_files': 0,
            'total_size': 0
        }
        
        if results_dir.exists():
            results_stats['json_files'] = len(list((results_dir / "json").glob("*.json"))) if (results_dir / "json").exists() else 0
            results_stats['csv_files'] = len(list((results_dir / "csv").glob("*.csv"))) if (results_dir / "csv").exists() else 0
            results_stats['txt_files'] = len(list((results_dir / "txt").glob("*.txt"))) if (results_dir / "txt").exists() else 0
            
            for subdir in results_dir.iterdir():
                if subdir.is_dir():
                    for file_path in subdir.rglob("*"):
                        if file_path.is_file():
                            try:
                                results_stats['total_size'] += file_path.stat().st_size
                            except:
                                continue
        
        # Exibir estat√≠sticas
        print(f"{Colors.BOLD}üíæ ESTAT√çSTICAS DE CACHE{Colors.RESET}")
        print(f"   Arquivos de cache: {Colors.CYAN}{cache_stats['total_files']}{Colors.RESET}")
        print(f"   Tamanho total: {Colors.GREEN}{cache_stats['total_size']/1024/1024:.1f}{Colors.RESET} MB")
        print(f"   √çndice: {Colors.YELLOW}{cache_stats['index_size']/1024:.1f}{Colors.RESET} KB")
        
        print(f"\n{Colors.BOLD}üîÑ SISTEMA INCREMENTAL{Colors.RESET}")
        checkpoint_status = f"{Colors.GREEN}‚úÖ Ativo{Colors.RESET}" if checkpoint_stats['incremental_available'] else f"{Colors.RED}‚ùå Inativo{Colors.RESET}"
        stats_status = f"{Colors.GREEN}‚úÖ Dispon√≠vel{Colors.RESET}" if checkpoint_stats['stats_available'] else f"{Colors.RED}‚ùå Indispon√≠vel{Colors.RESET}"
        print(f"   Checkpoint incremental: {checkpoint_status}")
        print(f"   Estat√≠sticas: {stats_status}")
        
        print(f"\n{Colors.BOLD}üìÅ ARQUIVOS DE RESULTADOS{Colors.RESET}")
        print(f"   Arquivos JSON: {Colors.GREEN}{results_stats['json_files']}{Colors.RESET}")
        print(f"   Arquivos CSV: {Colors.BLUE}{results_stats['csv_files']}{Colors.RESET}")
        print(f"   Arquivos TXT: {Colors.YELLOW}{results_stats['txt_files']}{Colors.RESET}")
        print(f"   Tamanho total: {Colors.MAGENTA}{results_stats['total_size']/1024/1024:.1f}{Colors.RESET} MB")
        
        # Efici√™ncia do sistema
        if checkpoint_stats['stats_available']:
            try:
                with open("data/checkpoints/incremental_stats.json", 'r') as f:
                    stats_data = json.load(f)
                
                print(f"\n{Colors.BOLD}üìä EFICI√äNCIA DO SISTEMA{Colors.RESET}")
                if 'deduplication' in stats_data:
                    dedup_stats = stats_data['deduplication']
                    print(f"   Duplicatas removidas: {Colors.RED}{dedup_stats.get('duplicates_removed', 0):,}{Colors.RESET}")
                    print(f"   Taxa de duplica√ß√£o: {Colors.YELLOW}{dedup_stats.get('duplication_rate', 0):.1f}%{Colors.RESET}")
                
                if 'compression' in stats_data:
                    comp_stats = stats_data['compression']
                    print(f"   Compress√£o de dados: {Colors.CYAN}{comp_stats.get('compression_ratio', 0):.1f}%{Colors.RESET}")
                
            except Exception as e:
                print(f"\n{Colors.RED}‚ùå Erro ao carregar estat√≠sticas incrementais: {e}{Colors.RESET}")
        
    except Exception as e:
        menu.print_error_message(f"Erro na an√°lise de performance: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def show_historical_data(menu):
    """Mostra dados hist√≥ricos e tend√™ncias"""
    menu.clear_screen()
    
    print(f"{Colors.BOLD}{Colors.PURPLE}üìà AN√ÅLISE HIST√ìRICA{Colors.RESET}")
    print()
    
    try:
        import json
        from pathlib import Path
        from collections import defaultdict
        from datetime import datetime
        
        # Carregar dados por arquivo (representando diferentes datas)
        results_dir = Path("data/resultados/json")
        historical_data = {}
        
        if results_dir.exists():
            for file_path in results_dir.glob("*.json"):
                try:
                    # Extrair data do nome do arquivo
                    filename = file_path.name
                    if "_" in filename:
                        date_part = filename.split("_")[-1].replace(".json", "")
                        if len(date_part) >= 8:
                            date_str = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                            
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            
                            if isinstance(data, list):
                                historical_data[date_str] = {
                                    'total_jobs': len(data),
                                    'jobs': data,
                                    'file': filename
                                }
                except:
                    continue
        
        if not historical_data:
            menu.print_warning_message("Nenhum dado hist√≥rico encontrado.")
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
            return
        
        # Ordenar por data
        sorted_dates = sorted(historical_data.keys())
        
        print(f"{Colors.BOLD}üìÖ EVOLU√á√ÉO TEMPORAL{Colors.RESET}")
        print()
        
        print(f"{'Data':<12} {'Vagas':<8} {'Arquivo':<30} {'Tend√™ncia'}")
        print("-" * 65)
        
        prev_count = 0
        for i, date in enumerate(sorted_dates):
            data = historical_data[date]
            count = data['total_jobs']
            
            # Calcular tend√™ncia
            if i == 0:
                trend = "üìä"
            elif count > prev_count:
                trend = f"üìà +{count - prev_count}"
            elif count < prev_count:
                trend = f"üìâ -{prev_count - count}"
            else:
                trend = "‚û°Ô∏è =0"
            
            print(f"{Colors.CYAN}{date}{Colors.RESET}   {Colors.GREEN}{count:>6,}{Colors.RESET}   {Colors.GRAY}{data['file'][:28]:<28}{Colors.RESET} {trend}")
            prev_count = count
        
        # An√°lise de tecnologias ao longo do tempo
        tech_timeline = defaultdict(lambda: defaultdict(int))
        
        for date, data in historical_data.items():
            for job in data['jobs']:
                for tech in job.get('tecnologias_detectadas', []):
                    tech_timeline[tech][date] += 1
        
        # Mostrar evolu√ß√£o das top 5 tecnologias
        if tech_timeline:
            print(f"\n{Colors.BOLD}üíª EVOLU√á√ÉO DAS TOP 5 TECNOLOGIAS{Colors.RESET}")
            
            # Calcular total por tecnologia
            tech_totals = {tech: sum(dates.values()) for tech, dates in tech_timeline.items()}
            top_techs = sorted(tech_totals.items(), key=lambda x: x[1], reverse=True)[:5]
            
            for tech, total in top_techs:
                print(f"\n{Colors.BOLD}{tech}{Colors.RESET} (Total: {total} men√ß√µes)")
                for date in sorted_dates:
                    count = tech_timeline[tech].get(date, 0)
                    if count > 0:
                        print(f"   {date}: {Colors.GREEN}{count:3d}{Colors.RESET} men√ß√µes")
        
        # Estat√≠sticas gerais
        if len(sorted_dates) > 1:
            first_date = sorted_dates[0]
            last_date = sorted_dates[-1]
            first_count = historical_data[first_date]['total_jobs']
            last_count = historical_data[last_date]['total_jobs']
            
            total_jobs = sum(data['total_jobs'] for data in historical_data.values())
            avg_jobs = total_jobs / len(historical_data)
            
            print(f"\n{Colors.BOLD}üìä RESUMO ESTAT√çSTICO{Colors.RESET}")
            print(f"   Per√≠odo analisado: {Colors.CYAN}{first_date}{Colors.RESET} a {Colors.CYAN}{last_date}{Colors.RESET}")
            print(f"   Total de coletas: {Colors.GREEN}{len(historical_data)}{Colors.RESET}")
            print(f"   Total de vagas: {Colors.GREEN}{total_jobs:,}{Colors.RESET}")
            print(f"   M√©dia por coleta: {Colors.YELLOW}{avg_jobs:.1f}{Colors.RESET}")
            
            if first_count != last_count:
                growth = ((last_count - first_count) / first_count) * 100
                growth_color = Colors.GREEN if growth > 0 else Colors.RED
                growth_symbol = "üìà" if growth > 0 else "üìâ"
                print(f"   Crescimento: {growth_color}{growth:+.1f}%{Colors.RESET} {growth_symbol}")
        
    except Exception as e:
        menu.print_error_message(f"Erro na an√°lise hist√≥rica: {e}")
    
    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


async def main():
    """Fun√ß√£o principal com menu melhorado"""
    menu = MenuSystem()
    
    while True:
        try:
            choice = menu.print_main_menu()
            
            if choice == "0":  # Sair
                menu.print_info_message("Obrigado por usar o Catho Job Scraper!")
                break
                
            elif choice == "1":  # Novo scraping
                config = menu.print_scraping_menu()
                if config:
                    await run_scraping_with_config(config)
                    input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")
                
            elif choice == "2":  # Buscar cache
                while True:
                    cache_choice = menu.print_cache_menu()
                    if cache_choice == "0":  # Voltar
                        break
                    else:
                        await handle_cache_operations(cache_choice)
                
            elif choice == "3":  # An√°lise de CV
                await handle_cv_analysis()
                
            elif choice == "4":  # Limpar dados
                await handle_clean_data()
                
            elif choice == "5":  # Deduplica√ß√£o
                await handle_deduplication()
                
            elif choice == "6":  # Configura√ß√µes
                await handle_settings_menu()
                
            elif choice == "7":  # Estat√≠sticas
                await handle_statistics_dashboard()
                
            elif choice == "8":  # API Server
                await start_api_server()
                
            elif choice == "9":  # Ajuda
                menu.print_help_menu()
                
        except KeyboardInterrupt:
            menu.print_info_message("Saindo...")
            break
        except Exception as e:
            menu.print_error_message(f"Erro inesperado: {e}")
            import traceback
            traceback.print_exc()
            input(f"\n{Colors.DIM}Pressione Enter para continuar...{Colors.RESET}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}üëã Saindo...{Colors.RESET}")
    except Exception as e:
        print(f"\n{Colors.RED}‚ùå Erro fatal: {e}{Colors.RESET}")