import asyncio
import sys
import os

# Adicionar pasta src ao path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.scraper import scrape_catho_jobs
from src.filters import JobFilter, get_filter_configuration
from src.utils import save_results


async def main():
    """
    Fun√ß√£o principal - vers√£o modularizada e organizada
    """
    print("=== WEB SCRAPER CATHO (VERS√ÉO MODULARIZADA) ===\n")
    print("‚ú® Projeto reorganizado com arquitetura modular:")
    print("   üì¶ cache.py - Sistema de cache inteligente")
    print("   üì¶ scraper.py - L√≥gica de scraping e extra√ß√£o")
    print("   üì¶ filters.py - Sistema de filtros avan√ßados")
    print("   üì¶ navigation.py - Navega√ß√£o multi-p√°gina")
    print("   üì¶ utils.py - Utilit√°rios e performance")
    print("   üì¶ main.py - Interface principal (este arquivo)")
    
    print("\nüîç Recursos dispon√≠veis:")
    print("   ‚Ä¢ Sistema de filtragem avan√ßada")
    print("   ‚Ä¢ Cache inteligente (6h de validade)")
    print("   ‚Ä¢ Rate limiting adaptativo")
    print("   ‚Ä¢ Navega√ß√£o por m√∫ltiplas p√°ginas")
    print("   ‚Ä¢ Processamento paralelo")
    print("   ‚Ä¢ An√°lise autom√°tica de dados")
    print("   ‚Ä¢ M√∫ltiplos formatos de sa√≠da\n")
    
    # Configurar filtros
    print("Deseja aplicar filtros √†s vagas? (s/n)")
    apply_filters = input().strip().lower() in ['s', 'sim', 'y', 'yes']
    
    filters_config = {}
    if apply_filters:
        filters_config = get_filter_configuration()
    else:
        print("‚úì Nenhum filtro ser√° aplicado - todas as vagas ser√£o coletadas")
    
    # Configurar performance
    print("\n‚ö° CONFIGURA√á√ÉO DE PERFORMANCE:")
    print("Quantas vagas processar simultaneamente? (1-5, padr√£o: 3)")
    try:
        max_concurrent = int(input("Digite o n√∫mero: ").strip() or "3")
        max_concurrent = max(1, min(5, max_concurrent))
    except:
        max_concurrent = 3
    
    print(f"‚úì Processamento paralelo: {max_concurrent} vagas simult√¢neas")
    
    # Configurar p√°ginas
    print("\nüìÑ CONFIGURA√á√ÉO DE P√ÅGINAS:")
    print("Quantas p√°ginas analisar? (1-10, padr√£o: 5)")
    try:
        max_pages = int(input("Digite o n√∫mero: ").strip() or "5")
        max_pages = max(1, min(10, max_pages))
    except:
        max_pages = 5
    
    print(f"‚úì Navega√ß√£o configurada: at√© {max_pages} p√°ginas")
    
    # Executando o scraper
    print(f"\n{'='*60}")
    print("INICIANDO COLETA COM ARQUITETURA MODULAR...")
    print(f"{'='*60}")
    
    jobs = await scrape_catho_jobs(max_concurrent_jobs=max_concurrent, max_pages=max_pages)
    
    if jobs:
        print(f"\n{'='*60}")
        print(f"DADOS COLETADOS: {len(jobs)} vagas encontradas")
        print(f"{'='*60}")
        
        # Aplicar filtros e an√°lise
        print("\nAplicando filtros e an√°lise...")
        job_filter = JobFilter()
        
        if filters_config:
            filtered_jobs = job_filter.apply_filters(jobs, filters_config)
            print(f"‚úì Filtros aplicados: {len(filtered_jobs)} vagas selecionadas")
        else:
            # Aplicar apenas an√°lise sem filtros
            filtered_jobs = job_filter.apply_filters(jobs, {})
            print(f"‚úì An√°lise aplicada a todas as {len(filtered_jobs)} vagas")
        
        jobs = filtered_jobs
        
        if jobs:
            print(f"\n{'='*60}")
            print(f"RESULTADO FINAL: {len(jobs)} vagas processadas")
            print(f"{'='*60}")
            
            # Salvando resultados
            save_results(jobs, filters_config)
            
            print(f"\n‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
            print(f"üìÅ Arquivos organizados em subdiret√≥rios")
            
            # Preview dos resultados
            print(f"\nüî• PREVIEW DOS RESULTADOS:")
            if jobs:
                # Tecnologias mais demandadas
                all_techs = {}
                for job in jobs:
                    for tech in job.get('tecnologias_detectadas', []):
                        all_techs[tech] = all_techs.get(tech, 0) + 1
                
                if all_techs:
                    print(f"   üíª Top 5 tecnologias:")
                    for tech, count in sorted(all_techs.items(), key=lambda x: x[1], reverse=True)[:5]:
                        print(f"      - {tech}: {count} vagas")
                
                # An√°lise de n√≠veis
                niveis = {}
                for job in jobs:
                    nivel = job.get('nivel_categorizado', 'N√£o categorizado')
                    niveis[nivel] = niveis.get(nivel, 0) + 1
                
                if niveis:
                    print(f"   üìä Distribui√ß√£o por n√≠vel:")
                    for nivel, count in sorted(niveis.items(), key=lambda x: x[1], reverse=True)[:3]:
                        print(f"      - {nivel.replace('_', ' ').title()}: {count} vagas")
        else:
            print("\n‚ö† Nenhuma vaga atendeu aos crit√©rios de filtro especificados.")
            print("Tente ajustar os filtros ou executar sem filtros.")
    else:
        print("\n‚úó Nenhuma vaga foi encontrada no site.")


if __name__ == "__main__":
    asyncio.run(main())